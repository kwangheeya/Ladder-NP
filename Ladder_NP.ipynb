{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ladder GNP\n",
    "For Pytorch 1.0.1, python 3.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.distributions import multivariate_normal, normal\n",
    "import torch.nn as nn\n",
    "\n",
    "import collections, copy\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        out_dim = output_size\n",
    "        for i, size in enumerate(hidden_sizes):\n",
    "            in_dim = input_size if i == 0 else hidden_sizes[i-1]\n",
    "            out_dim = size \n",
    "            layers += [nn.Linear(in_dim, out_dim), nn.ReLU()]\n",
    "        # Last layer without a ReLU\n",
    "        layers += [nn.Linear(out_dim, output_size)]\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "                   \n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, a_dim, z_dim):\n",
    "        \"\"\"\n",
    "          input_size: raw input size = d_x + d_y\n",
    "          hidden_sizes: The dimensions of hidden layers of the encoding MLP.\n",
    "          a_dim: aggregation vector dimension.\n",
    "          z_dim: the size of dropout weigths\n",
    "          \n",
    "          a_mlp: input_size -> hidden_sizes -> a_dim = aggregation vector\n",
    "          z_mlp: a_dim -> hidden_sizes -> z_dim = z distribution\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.a_mlp = MLP(input_size, hidden_sizes, a_dim)\n",
    "        self.g_mlp = MLP(input_size, hidden_sizes, a_dim)\n",
    "        self.z_dim = z_dim\n",
    "        self.z_mlp = MLP(a_dim, hidden_sizes, z_dim*2)\n",
    "        self.embeddings = None\n",
    "        self._softplus = nn.Softplus()\n",
    "        \n",
    "    def _to_one_hot(self, y, n_dims, dtype=torch.cuda.FloatTensor):\n",
    "        scatter_dim = len(y.size())\n",
    "        y_tensor = y.type(torch.cuda.LongTensor).view(*y.size(), -1)\n",
    "        zeros = torch.zeros(*y.size(), n_dims).type(dtype)\n",
    "\n",
    "        return zeros.scatter(scatter_dim, y_tensor, 1)   \n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        \"\"\"Encodes the inputs into one representation.\n",
    "\n",
    "        Args:\n",
    "          x: Tensor of shape [Batches,contexts,d_x]. For this 1D regression\n",
    "              task this corresponds to the x-values.\n",
    "          y: Tensor of shape [B,contexts,d_y]. For this 1D regression\n",
    "              task this corresponds to the y-values.\n",
    "\n",
    "        Returns:\n",
    "          A normal distribution over tensors of shape [B, z_dim]\n",
    "        \"\"\"\n",
    "        '''\n",
    "        num_context = x.size(1)\n",
    "        bins = (self.z_dim*(x+2)*0.25).int()\n",
    "        masked = self._to_one_hot(bins, self.z_dim).squeeze(-2)\n",
    "        masked = torch.max(masked, dim=1)[0]\n",
    "        #print(masked[0])\n",
    "        masked = (masked).unsqueeze(1).repeat([1, num_context, 1])\n",
    "        #print(masked[0])\n",
    "        '''\n",
    "        # Concatenate x and y along the filter axes\n",
    "        encoder_input = torch.cat([x, y], dim=-1)\n",
    "\n",
    "        # Pass final axis through MLP\n",
    "        es = self.a_mlp(encoder_input)\n",
    "        #gs = self.g_mlp(encoder_input)\n",
    "        #gs = self.g_mlp(encoder_input).masked_fill(masked==0, -1e9) # B C d\n",
    "        #B, C, d = gs.shape\n",
    "        #gs = torch.tanh(gs)\n",
    "        #gs = torch.softmax(gs, dim=1)\n",
    "\n",
    "        hidden = torch.mean(es, dim=1)\n",
    "        self.embeddings = hidden\n",
    "        #z_sigma = g_tilda*0.1 + (1-g_tilda)*1.0\n",
    "\n",
    "\n",
    "        # Produce mu & sigma\n",
    "        hidden = self.z_mlp(hidden)\n",
    "        \n",
    "        z_mu, log_sigma = torch.split(hidden, self.z_dim, dim=-1)\n",
    "\n",
    "        z_sigma = 0.1 + 0.9 * self._softplus(log_sigma)\n",
    "\n",
    "        z_dist = normal.Normal(z_mu, z_sigma)\n",
    "        \n",
    "        return z_dist, z_mu, z_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_size, x_input_size, hidden_sizes, output_size):        \n",
    "        \"\"\"\n",
    "          input_size: d_x + dimension of z\n",
    "          hidden_sizes: The dimensions of hidden layers of the decoding MLP. \n",
    "          output_size: d_y\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.output_size = output_size\n",
    "        self._mlp = MLP(input_size + x_input_size, hidden_sizes, output_size*2)\n",
    "        #self.g_mlp = MLP(x_input_size, hidden_sizes, input_size)\n",
    "        self._softplus = nn.Softplus()\n",
    "\n",
    "    def forward(self, target_x, representation):\n",
    "        \"\"\"Decodes the individual targets.\n",
    "\n",
    "        Args:\n",
    "          target_x: The x locations for the target query.\n",
    "              Tensor of shape [B,targets,d_x].\n",
    "          representation: The representation of the context for target predictions. \n",
    "              Tensor of shape [B,z_dim].\n",
    "              z_dim = sum(hidden_sizes)\n",
    "\n",
    "        Returns:\n",
    "          dist: A multivariate Gaussian over the target points. A distribution over\n",
    "              tensors of shape [B,targets,d_y].\n",
    "          mu: The mean of the multivariate Gaussian.\n",
    "              Tensor of shape [B,targets,d_y].\n",
    "          sigma: The standard deviation of the multivariate Gaussian.\n",
    "              Tensor of shape [B,targets,d_y].\n",
    "        \"\"\"\n",
    "        # Pass final axis through MLP\n",
    "        #x = self.g_mlp(target_x)\n",
    "        num_targets = target_x.shape[1]\n",
    "        representation = representation.unsqueeze(1).repeat([1, num_targets, 1])\n",
    "        #representation = representation*gs\n",
    "        hidden = torch.cat([representation, target_x], dim=-1)\n",
    "        hidden = self._mlp(hidden)\n",
    "        mu, log_sigma = torch.split(hidden, self.output_size, dim=-1)\n",
    "\n",
    "        # Bound the variance\n",
    "        sigma = 0.1 + 0.9 * self._softplus(log_sigma)\n",
    "        \n",
    "        # Get the distribution\n",
    "        dist = normal.Normal(mu, sigma) #multivariate, but, diagonal covariance matrix\n",
    "\n",
    "        return dist, mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZMLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size):        \n",
    "        \"\"\"\n",
    "          input_size: d_x + dimension of z\n",
    "          hidden_sizes: The dimensions of hidden layers of the decoding MLP. \n",
    "          output_size: d_y\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.output_size = output_size\n",
    "        self._mlp = MLP(input_size, hidden_sizes, output_size*2)\n",
    "\n",
    "    def forward(self, z):\n",
    "        \"\"\"Decodes the individual targets.\n",
    "\n",
    "        Args:\n",
    "          target_x: The x locations for the target query.\n",
    "              Tensor of shape [B,targets,d_x].\n",
    "          representation: The representation of the context for target predictions. \n",
    "              Tensor of shape [B,z_dim].\n",
    "              z_dim = sum(hidden_sizes)\n",
    "\n",
    "        Returns:\n",
    "          dist: A multivariate Gaussian over the target points. A distribution over\n",
    "              tensors of shape [B,targets,d_y].\n",
    "          mu: The mean of the multivariate Gaussian.\n",
    "              Tensor of shape [B,targets,d_y].\n",
    "          sigma: The standard deviation of the multivariate Gaussian.\n",
    "              Tensor of shape [B,targets,d_y].\n",
    "        \"\"\"\n",
    "        hidden = self._mlp(z)\n",
    "        mu, log_sigma = torch.split(hidden, self.output_size, dim=-1)\n",
    "\n",
    "        # Bound the variance\n",
    "        sigma = 0.1 + 0.9 * torch.sigmoid(log_sigma)\n",
    "\n",
    "        return mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropoutNeurlProcess(nn.Module):\n",
    "    def __init__(self, input_sizes, encoder_hidden_sizes, a_dim, decoder_hidden_sizes):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          input_sizes: [d_x, d_y]\n",
    "          encoder_hidden_sizes: [eh1, eh2]\n",
    "          a_dim:\n",
    "          decoder_hidden_sizes: [dh1, dh2, dh3]\n",
    "        \"\"\"\n",
    "        super().__init__()    \n",
    "        \n",
    "        z_dim = a_dim\n",
    "        self.encoder = Encoder(sum(input_sizes), encoder_hidden_sizes, a_dim, z_dim)\n",
    "        self.decoder = Decoder(z_dim, input_sizes[0], decoder_hidden_sizes, input_sizes[1])\n",
    "        self.z_mlp = ZMLP(z_dim, encoder_hidden_sizes, z_dim)\n",
    "        self.l_mlp = ZMLP(z_dim, encoder_hidden_sizes, z_dim)\n",
    "        self.d_mlp = MLP(z_dim, encoder_hidden_sizes, z_dim)\n",
    "        self.z_dim = z_dim\n",
    "        self.device = \"cpu\"\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = \"cuda\"\n",
    "            \n",
    "    def sample_z(self, mu, sigma, dist=None):\n",
    "        \"\"\"Reparametrization trick\n",
    "        \"\"\"\n",
    "        eps = torch.randn(sigma.shape) \n",
    "        if torch.cuda.is_available():\n",
    "            eps = eps.cuda()\n",
    "        return mu + sigma * eps\n",
    "\n",
    "    def gaussian_product(self, mu1, sigma1, mu2, sigma2):\n",
    "        sigma = sigma1*sigma2/torch.sqrt(sigma1.pow(2)+sigma2.pow(2))\n",
    "        mu = (mu1/(sigma1.pow(2)) + mu2/(sigma2.pow(2)))*(sigma.pow(2))\n",
    "        return mu, sigma\n",
    "    \n",
    "    def _KL(self, mu, sigma, mup, sigmap):\n",
    "        t = 2.0*torch.log(sigmap) - 2.0*torch.log(sigma) + (sigma.pow(2))* (1.0/sigmap.pow(2)) + (1.0/sigmap.pow(2))*((mu-mup).pow(2))-1.0\n",
    "        return t*0.5\n",
    "    \n",
    "    def forward(self, context_x, context_y, target_x, target_y=None, beta=1.0):\n",
    "        \"\"\"Returns the predicted mean and variance at the target points.\n",
    "\n",
    "        Args:\n",
    "          context_x: Tensor of shape [B,num_contexts,d_x]. \n",
    "              Contains the x values of the context points.\n",
    "          context_y: Tensor of shape [B,num_contexts,d_y]. \n",
    "              Contains the y values of the context points.\n",
    "          target_x: Tensor of shape [B,num_targets,d_x]. \n",
    "              Contains the x values of the target points.\n",
    "          target_y: The ground truth y values of the target y. \n",
    "              Tensor of shape [B,num_targets,d_y].\n",
    "\n",
    "        Returns:\n",
    "          log_p: The log_probability of the target_y given the predicted\n",
    "              distribution. Tensor of shape [B,num_targets].\n",
    "          mu: The mean of the predicted distribution. \n",
    "              Tensor of shape [B,num_targets,d_y].\n",
    "          sigma: The variance of the predicted distribution.\n",
    "              Tensor of shape [B,num_targets,d_y].\n",
    "        \"\"\"\n",
    "          \n",
    "        num_batch = context_x.size(0)\n",
    "        \n",
    "        mu, sigma, log_p, loss = None, None, None, None\n",
    "        dkl = None\n",
    "        \n",
    "        _, mu_p_3, sigma_p_3 = self.encoder(context_x, context_y)\n",
    "        z3 = self.sample_z(mu_p_3, sigma_p_3)\n",
    "        mu_p_2, sigma_p_2 = self.z_mlp(z3)\n",
    "        z2 = self.sample_z(mu_p_2, sigma_p_2)\n",
    "        mu_p_1, sigma_p_1 = self.z_mlp(z2)\n",
    "\n",
    "        if target_y is None:\n",
    "            # Prediction\n",
    "            z1 = self.sample_z(mu_p_1, sigma_p_1)\n",
    "            dist, mu, sigma = self.decoder(target_x, z1)\n",
    "        else:\n",
    "            # Inference\n",
    "            _, mu_q_3, sigma_q_3  = self.encoder(target_x, target_y)\n",
    "            embeddings = self.encoder.embeddings\n",
    "            d_1 = self.d_mlp(embeddings)\n",
    "            d_2 = self.d_mlp(d_1)\n",
    "            mu_h_q_2, sigma_h_q_2 = self.l_mlp(d_2)\n",
    "            mu_q_2, sigma_q_2 = self.gaussian_product(mu_p_2, sigma_p_2, mu_h_q_2, sigma_h_q_2)\n",
    "            mu_h_q_1, sigma_h_q_1 = self.l_mlp(d_1)\n",
    "            mu_q_1, sigma_q_1 = self.gaussian_product(mu_p_1, sigma_p_1, mu_h_q_1, sigma_h_q_1)            \n",
    "            z1 = self.sample_z(mu_q_1, sigma_q_1)    \n",
    "\n",
    "            dist, mu, sigma = self.decoder(target_x, z1)\n",
    "            log_p = dist.log_prob(target_y)\n",
    "            log_p = log_p.squeeze(-1)       \n",
    "            \n",
    "            num_targets = target_x.size(1)\n",
    "            dkl3 = torch.sum(self._KL(mu_q_3, sigma_q_3, mu_p_3, sigma_p_3),\n",
    "                  dim=-1, keepdim=True)\n",
    "            dkl3 = dkl3.repeat([1, num_targets])\n",
    "            dkl2 = torch.sum(self._KL(mu_q_2, sigma_q_2, mu_p_2, sigma_p_2),\n",
    "                  dim=-1, keepdim=True)\n",
    "            dkl2 = dkl2.repeat([1, num_targets])\n",
    "            dkl1 = torch.sum(self._KL(mu_q_1, sigma_q_1, mu_p_1, sigma_p_1),\n",
    "                  dim=-1, keepdim=True)\n",
    "            dkl1 = dkl1.repeat([1, num_targets])\n",
    "            loss = - torch.mean(log_p - beta * (dkl1+dkl2+dkl3) / num_targets)\n",
    "          \n",
    "            \n",
    "        return mu, dkl, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    HIDDEN_SIZE = 128 #@param {type:\"number\"}\n",
    "    input_sizes = [2, 1]\n",
    "    encoder_hidden_sizes = [HIDDEN_SIZE]*3\n",
    "    decoder_hidden_sizes = [HIDDEN_SIZE]*4\n",
    "    model = DropoutNeurlProcess(input_sizes, encoder_hidden_sizes, HIDDEN_SIZE, decoder_hidden_sizes)\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
